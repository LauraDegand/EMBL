{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2da6fd47-15da-489a-8868-fc39982df2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "206c872e-e42f-4490-abeb-704c00ee7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = glob.glob('./rescaled/train/images/*.tif')\n",
    "train_labels = glob.glob('./rescaled/train/labels/*.tif')\n",
    "\n",
    "val_images = glob.glob('./rescaled/validation/images/*.tif')\n",
    "val_labels = glob.glob('./rescaled/validation/labels/*.tif')\n",
    "\n",
    "test_images = glob.glob('./rescaled/test/images/*.tif')\n",
    "test_labels = glob.glob('./rescaled/test/labels/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0209ecad-b9d2-405d-87cb-5243536bf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_images)==len(train_labels)\n",
    "assert len(val_images)==len(val_labels)\n",
    "assert len(test_images)==len(test_labels)\n",
    "\n",
    "print(\"Have\", len(train_images), \"training images and\", len(val_images), \"validation images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b871d07-3b42-4fb5-afc2-c59b9924578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from functools import partial\n",
    "\n",
    "def normalize(image, target, channel_wise=True):\n",
    "    eps = 1.e-6\n",
    "    image = image.astype('float32')\n",
    "    chan_min = image.min(axis=(1, 2), keepdims=True)\n",
    "    image -= chan_min\n",
    "    chan_max = image.max(axis=(1, 2), keepdims=True)\n",
    "    image /= (chan_max + eps)\n",
    "    return image, target\n",
    "\n",
    "#def to_tensor():\n",
    "    \n",
    "#image = train_images[1]\n",
    "#normalize(image , \n",
    "#def DatasetWithTransform(images , labels , transform)\n",
    "\n",
    "\n",
    "def get_loader(train_images, train_labels, patch_shape, split):\n",
    "    data_paths = glob(os.path.join(args.input, split, \"*.h5\"))\n",
    "    assert len(data_paths) > 0\n",
    "    n_samples = 100 if split == \"train\" else 4\n",
    "    loader = torch_em.default_segmentation_loader(\n",
    "        data_paths, \"image\", data_paths, \"labels\",\n",
    "        label_transform=microct_label_transform,\n",
    "        batch_size=args.batch_size, patch_shape=patch_shape,\n",
    "        num_workers=8, shuffle=True, is_seg_dataset=True,\n",
    "        n_samples=n_samples\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0801dd7-a686-40f8-be0f-1882ab773939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_em.model import UNet3d\n",
    "\n",
    "def train(train_images , train_labels):\n",
    "    number_labels = 4\n",
    "    model = UNet3d(in_channels=1, out_channels=n_out, final_activation=\"Sigmoid\")\n",
    "\n",
    "    patch_shape = [128, 128, 128]\n",
    "\n",
    "    train_loader = get_loader(train_images , train_labels, patch_shape, \"train\")\n",
    "    #val_loader = get_loader(val, patch_shape, \"val\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68bd0ceb-aed3-4632-a448-69ea00dcafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\" UNet implementation\n",
    "    Arguments:\n",
    "      in_channels: number of input channels\n",
    "      out_channels: number of output channels\n",
    "      final_activation: activation applied to the network output\n",
    "    \"\"\"\n",
    "    \n",
    "    # _conv_block and _upsampler are just helper functions to\n",
    "    # construct the model.\n",
    "    # encapsulating them like so also makes it easy to re-use\n",
    "    # the model implementation with different architecture elements\n",
    "    \n",
    "    # Convolutional block for single layer of the decoder / encoder\n",
    "    # we apply to 2d convolutions with relu activation\n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                             nn.ReLU())       \n",
    "\n",
    "\n",
    "    # upsampling via transposed 2d convolutions\n",
    "    def _upsampler(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels,\n",
    "                                kernel_size=2, stride=2)\n",
    "    \n",
    "    def __init__(self, in_channels=1, out_channels=1, \n",
    "                 final_activation=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the depth (= number of encoder / decoder levels) is\n",
    "        # hard-coded to 4\n",
    "        self.depth = 4\n",
    "\n",
    "        # the final activation must either be None or a Module\n",
    "        if final_activation is not None:\n",
    "            assert isinstance(final_activation, nn.Module), \"Activation must be torch module\"\n",
    "        \n",
    "        # all lists of conv layers (or other nn.Modules with parameters) must be wraped\n",
    "        # itnto a nn.ModuleList\n",
    "        \n",
    "        # modules of the encoder path\n",
    "        self.encoder = nn.ModuleList([self._conv_block(in_channels, 16),\n",
    "                                      self._conv_block(16, 32),\n",
    "                                      self._conv_block(32, 64),\n",
    "                                      self._conv_block(64, 128)])\n",
    "        # the base convolution block\n",
    "        self.base = self._conv_block(128, 256)\n",
    "        # modules of the decoder path\n",
    "        self.decoder = nn.ModuleList([self._conv_block(256, 128),\n",
    "                                      self._conv_block(128, 64),\n",
    "                                      self._conv_block(64, 32),\n",
    "                                      self._conv_block(32, 16)])\n",
    "        \n",
    "        # the pooling layers; we use 2x2 MaxPooling\n",
    "        self.poolers = nn.ModuleList([nn.MaxPool2d(2) for _ in range(self.depth)])\n",
    "        # the upsampling layers\n",
    "        self.upsamplers = nn.ModuleList([self._upsampler(256, 128),\n",
    "                                         self._upsampler(128, 64),\n",
    "                                         self._upsampler(64, 32),\n",
    "                                         self._upsampler(32, 16)])\n",
    "        # output conv and activation\n",
    "        # the output conv is not followed by a non-linearity, because we apply\n",
    "        # activation afterwards\n",
    "        self.out_conv = nn.Conv2d(16, out_channels, 1)\n",
    "        self.activation = final_activation\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        # apply encoder path\n",
    "        encoder_out = []\n",
    "        for level in range(self.depth):\n",
    "            x = self.encoder[level](x)\n",
    "            encoder_out.append(x)\n",
    "            x = self.poolers[level](x)\n",
    "\n",
    "        # apply base\n",
    "        x = self.base(x)\n",
    "        \n",
    "        # apply decoder path\n",
    "        encoder_out = encoder_out[::-1]\n",
    "        for level in range(self.depth):\n",
    "            x = self.upsamplers[level](x)\n",
    "            x = self.decoder[level](torch.cat((x, encoder_out[level]), dim=1))\n",
    "        \n",
    "        # apply output conv and activation (if given)\n",
    "        x = self.out_conv(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e544b-502e-4c2f-83a3-25dd307cb649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3bbf6e-d67e-4fc5-aaf1-5533a6817689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b73cd141-ec91-42e3-8cf2-200c20f041d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# check if we have  a gpu\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e0444a4-1dc1-45ef-ab8c-e147f23cfa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 1318), started 0:05:13 ago. (Use '!kill 1318' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e77e3592345636ea\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e77e3592345636ea\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a tensorboard writer\n",
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "logger = SummaryWriter('runs/Unet')\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "004d5110-fb24-44b6-8c86-dda00afe06ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3d(\n",
       "  (encoder): Encoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (poolers): ModuleList(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (base): ConvBlock3d(\n",
       "    (block): Sequential(\n",
       "      (0): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (4): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvBlock3d(\n",
       "        (block): Sequential(\n",
       "          (0): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (samplers): ModuleList(\n",
       "      (0): Upsampler3d(\n",
       "        (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): Upsampler3d(\n",
       "        (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (2): Upsampler3d(\n",
       "        (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (3): Upsampler3d(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (final_activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a default unet with sigmoid activation\n",
    "# to normalize predictions to [0, 1]\n",
    "from torch_em.model import UNet3d\n",
    "model = UNet3d(1, 1, final_activation=nn.Sigmoid())\n",
    "# move the model to GPU\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526de45-5bcc-487d-8b24-d7ead851fc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8dee1-f35d-4d55-b15a-c4b09912a4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
