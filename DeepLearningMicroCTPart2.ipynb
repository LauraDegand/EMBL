{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39063123-0614-4d48-a63e-2e25523a2ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: XDG_RUNTIME_DIR points to non-existing path '/run/user/1043', please create it with 0700 permissions.\n"
     ]
    }
   ],
   "source": [
    "%gui qt5\n",
    "%load_ext tensorboard\n",
    "\n",
    "from skimage import data\n",
    "import napari\n",
    "import imageio\n",
    "import glob\n",
    "from skimage.transform import rescale\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73f4fee-a77c-40bf-abbd-94598110fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrosoMicroCT(Dataset):\n",
    "    '''A dataset to load microCT scans of Drosophila and organ segmentations'''\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir  # the directory with all the training samples\n",
    "        self.samples = os.listdir(os.path.join(root_dir,  'images')) # list the samples\n",
    "        self.transform = transform    # transformations to apply to both inputs and targets\n",
    "        #  transformations to apply just to inputs\n",
    "        self.inp_transforms = transforms.Compose([transforms.Normalize([0.5], [0.5])])\n",
    "        # self.inp_transforms = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
    "        # transformations to apply just to targets\n",
    "        #self.mask_transforms = torch.tensor()\n",
    "        \n",
    "        # get the total number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    # fetch the training sample given its index\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir,\n",
    "                                'images', self.samples[idx])\n",
    "        image = imageio.volread(img_path)\n",
    "        image = torch.tensor(image)\n",
    "        image = self.inp_transforms(image)\n",
    "        labels_path = os.path.join(self.root_dir, 'labels', self.samples[idx].replace('Rec', 'Rec_labels'))\n",
    "        labels = imageio.volread(labels_path)\n",
    "        labels = torch.tensor(labels)\n",
    "        labels[labels == 4] = 3 #converts ovaries to same label\n",
    "        image = torch.unsqueeze(image, dim=0)\n",
    "        labels = torch.unsqueeze(labels, dim=0)\n",
    "        if self.transform is not None:\n",
    "            image, labels = self.transform([image, labels])\n",
    "        return image.type(torch.FloatTensor), labels.type(torch.FloatTensor)\n",
    "        #return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5bff88-0fda-4899-bad5-3609db60ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DrosoMicroCT('./Project5_Drosophila_microCT_segmentation/resize2/train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "val_data = DrosoMicroCT('./Project5_Drosophila_microCT_segmentation/resize2/val')\n",
    "val_loader = DataLoader(val_data, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7f9e30-a3a5-4099-99e8-e8dc5ffa86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\" UNet implementation\n",
    "    Arguments:\n",
    "      in_channels: number of input channels\n",
    "      out_channels: number of output channels\n",
    "      final_activation: activation applied to the network output\n",
    "    \"\"\"\n",
    "    \n",
    "    # _conv_block and _upsampler are just helper functions to\n",
    "    # construct the model.\n",
    "    # encapsulating them like so also makes it easy to re-use\n",
    "    # the model implementation with different architecture elements\n",
    "    \n",
    "    # Convolutional block for single layer of the decoder / encoder\n",
    "    # we apply to 3d convolutions with relu activation\n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                             nn.ReLU())       \n",
    "\n",
    "\n",
    "    # upsampling via transposed 3d convolutions\n",
    "    def _upsampler(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose3d(in_channels, out_channels,\n",
    "                                kernel_size=2, stride=2)\n",
    "    \n",
    "    def __init__(self, in_channels=1, out_channels=1, \n",
    "                 final_activation=None):  #nn.Sigmoid): #None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # the depth (= number of encoder / decoder levels) is\n",
    "        # hard-coded to 4\n",
    "        self.depth = 4\n",
    "\n",
    "        # the final activation must either be None or a Module\n",
    "        if final_activation is not None:\n",
    "            assert isinstance(final_activation, nn.Module), \"Activation must be torch module\"\n",
    "        \n",
    "        # all lists of conv layers (or other nn.Modules with parameters) must be wraped\n",
    "        # itnto a nn.ModuleList\n",
    "        \n",
    "        # modules of the encoder path\n",
    "        self.encoder = nn.ModuleList([self._conv_block(in_channels, 16),\n",
    "                                      self._conv_block(16, 32),\n",
    "                                      self._conv_block(32, 64),\n",
    "                                      self._conv_block(64, 128)])\n",
    "        # the base convolution block\n",
    "        self.base = self._conv_block(128, 256)\n",
    "        # modules of the decoder path\n",
    "        self.decoder = nn.ModuleList([self._conv_block(256, 128),\n",
    "                                      self._conv_block(128, 64),\n",
    "                                      self._conv_block(64, 32),\n",
    "                                      self._conv_block(32, 16)])\n",
    "        \n",
    "        # the pooling layers; we use 2x2 MaxPooling\n",
    "        self.poolers = nn.ModuleList([nn.MaxPool3d(2) for _ in range(self.depth)])\n",
    "        # the upsampling layers\n",
    "        self.upsamplers = nn.ModuleList([self._upsampler(256, 128),\n",
    "                                         self._upsampler(128, 64),\n",
    "                                         self._upsampler(64, 32),\n",
    "                                         self._upsampler(32, 16)])\n",
    "        # output conv and activation\n",
    "        # the output conv is not followed by a non-linearity, because we apply\n",
    "        # activation afterwards\n",
    "        self.out_conv = nn.Conv3d(16, out_channels, 1)\n",
    "        self.activation = final_activation\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        # apply encoder path\n",
    "        encoder_out = []\n",
    "        for level in range(self.depth):\n",
    "            x = self.encoder[level](x)\n",
    "            encoder_out.append(x)\n",
    "            x = self.poolers[level](x)\n",
    "\n",
    "        # apply base\n",
    "        x = self.base(x)\n",
    "        \n",
    "        # apply decoder path\n",
    "        encoder_out = encoder_out[::-1]\n",
    "        for level in range(self.depth):\n",
    "            x = self.upsamplers[level](x)\n",
    "            x = self.decoder[level](torch.cat((x, encoder_out[level]), dim=1))\n",
    "        \n",
    "        # apply output conv and activation (if given)\n",
    "        x = self.out_conv(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        #x = nn.Sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56c0c90-79c2-4030-a9b7-427a88e49fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorensen dice coefficient implemented in torch\n",
    "# the coefficient takes values in [0, 1], where 0 is\n",
    "# the worst score, 1 is the best score\n",
    "class DiceCoefficient(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    # the dice coefficient of two sets represented as vectors a, b ca be \n",
    "    # computed as (2 *|a b| / (a^2 + b^2))\n",
    "    def forward(self, prediction, target):\n",
    "        intersection = (prediction * target).sum()\n",
    "        denominator = (prediction * prediction).sum() + (target * target).sum()\n",
    "        return (2 * intersection / denominator.clamp(min=self.eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c05879-b5bc-471c-a536-fe5cae497a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# check if we have  a gpu\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69f4d0a6-0fe1-41a8-8a3c-f622f6662164",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(1, 4)  #, final_activation=nn.Sigmoid()) #second '1' changed to 4\n",
    "model = model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1.e-3)\n",
    "metric = DiceCoefficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe06170-791e-44f7-a6c0-14747d3105a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e276d088445506b0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e276d088445506b0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6556;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a tensorboard writer\n",
    "tb_logger = SummaryWriter('runs/Unet')\n",
    "%tensorboard --logdir runs  --port 6556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52a50662-4230-49dc-bb63-1efdcafb40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply training for one epoch\n",
    "def train(model, loader, loss_function, optimizer, device,\n",
    "          epoch, log_interval=100, log_image_interval=20, tb_logger=None):\n",
    "    \"\"\" Train model for one epoch.\n",
    "\n",
    "    Parameters:\n",
    "    model - the model we are training\n",
    "    loader - the data loader that provides the training data\n",
    "        (= pairs of images and labels)\n",
    "    loss_function - the loss function that will be optimized\n",
    "    optimizer - the optimizer that is used to update the network parameters\n",
    "        by backpropagation of the loss\n",
    "    device - the device used for training. this can either be the cpu or gpu\n",
    "    epoch - which trainin eppch are we in? we keep track of this for logging\n",
    "    tb_logger - the tensorboard logger, it is used to communicate with tensorboard\n",
    "    log_image_interval - how often do we send images to tensborboard?\n",
    "    \"\"\"\n",
    "\n",
    "    # set the model to train mode TODO: YOUR CODE HERE\n",
    "    model.train()\n",
    "    #n_batches = len(loader)\n",
    "\n",
    "    # iterate over the batches of this epoch\n",
    "    for batch_id, (x, y) in enumerate(loader):\n",
    "        # move input and target to the active device (either cpu or gpu)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # zero the gradients for this iteration TODO: YOUR CODE HERE\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # apply model, calculate loss and run backwards pass TODO: YOUR CODE HERE\n",
    "        prediction = model(x)\n",
    "        #prediction = torch.argmax(prediction, dim = 1)\n",
    "        #prediction = prediction.float()\n",
    "        #print(prediction.shape)\n",
    "        #print(torch.unique(prediction))\n",
    "        #print(torch.unique(x))\n",
    "        #print(torch.unique(y))\n",
    "        #print(y[:, 0].shape)\n",
    "        #prediction = prediction.long()\n",
    "        y = y.long()\n",
    "        #loss_value = loss_function(prediction, y)\n",
    "        loss_value = loss_function(prediction, y[:, 0])\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # log to console\n",
    "        if batch_id % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                  epoch, batch_id * len(x),\n",
    "                  len(loader.dataset),\n",
    "                  100. * batch_id / len(loader), loss_value.item()))\n",
    "\n",
    "       # log to tensorboard\n",
    "        if tb_logger is not None:\n",
    "            step = epoch * len(loader) + batch_id\n",
    "            tb_logger.add_scalar(tag='train_loss', scalar_value=loss_value.item(), global_step=step)\n",
    "            # check if we log images in this iteration\n",
    "            if step % log_image_interval == 0:\n",
    "                tb_logger.add_images(tag='input', img_tensor=x[:,:,50,:,:].to('cpu'), global_step=step)\n",
    "                tb_logger.add_images(tag='target', img_tensor=y[:,:,50,:,:].to('cpu'), global_step=step)\n",
    "                #tb_logger.add_images(tag='prediction', img_tensor=prediction[:,1,50,:,:].to('cpu').detach(), global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b013f562-64b0-409a-b05f-6e253a9a5506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run validation after training epoch\n",
    "def validate(model, loader, loss_function, metric, step=None, tb_logger=None):\n",
    "    # set model to eval mode TODO: YOUR CODE HERE\n",
    "    model.eval()\n",
    "    #n_batches = len(loader)\n",
    "    \n",
    "    # running loss and metric values\n",
    "    val_loss = 0\n",
    "    val_metric = 0\n",
    "    \n",
    "    # disable gradients during validation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # iterate over validation loader and update loss and metric values\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            #TODO: YOUR CODE HERE\n",
    "            prediction = model(x)\n",
    "            y = y.long()\n",
    "            #mean_loss += loss_function(prediction, y[:, 0]).item()\n",
    "            val_loss += loss_function(prediction, y[:,0]).item()\n",
    "            val_metric += metric(prediction, y).item()\n",
    "            \n",
    "            #prediction = prediction.max(1, keepdim=True)[1]\n",
    "            #predictions.append(prediction[:, 0].to('cpu').numpy())\n",
    "            #labels.append(y[:, 0].to('cpu').numpy())\n",
    "        #predictions = np.concatenate(predictions)\n",
    "        #labels = np.concatenate(labels)\n",
    "        \n",
    "    # normalize loss and metric\n",
    "    val_loss /= len(loader)\n",
    "    val_metric /= len(loader)\n",
    "    \n",
    "    if tb_logger is not None:\n",
    "        assert step is not None, \"Need to know the current step to log validation results\"\n",
    "        tb_logger.add_scalar(tag='val_loss', scalar_value=val_loss, global_step=step)\n",
    "        tb_logger.add_scalar(tag='val_metric', scalar_value=val_metric, global_step=step)\n",
    "        # we always log the last validation images\n",
    "        tb_logger.add_images(tag='val_input', img_tensor=x[:,:,50,:,:].to('cpu'), global_step=step)\n",
    "        tb_logger.add_images(tag='val_target', img_tensor=y[:,:,50,:,:].to('cpu'), global_step=step)\n",
    "        #tb_logger.add_images(tag='val_prediction', img_tensor=prediction[...,50,:,:].to('cpu'), global_step=step)\n",
    "        \n",
    "    print('\\nValidate: Average loss: {:.4f}, Average Metric: {:.4f}\\n'.format(val_loss, val_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceae30a8-1041-4b19-a975-2767d7d324ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/57 (0%)]\tLoss: 1.859687\n",
      "\n",
      "Validate: Average loss: 0.5864, Average Metric: 0.0005\n",
      "\n",
      "Train Epoch: 1 [0/57 (0%)]\tLoss: 0.679570\n",
      "\n",
      "Validate: Average loss: 0.1935, Average Metric: 0.0000\n",
      "\n",
      "Train Epoch: 2 [0/57 (0%)]\tLoss: 0.297269\n",
      "\n",
      "Validate: Average loss: 0.1924, Average Metric: 0.0000\n",
      "\n",
      "Train Epoch: 3 [0/57 (0%)]\tLoss: 0.227704\n",
      "\n",
      "Validate: Average loss: 0.1777, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 4 [0/57 (0%)]\tLoss: 0.136207\n",
      "\n",
      "Validate: Average loss: 0.1739, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 5 [0/57 (0%)]\tLoss: 0.177627\n",
      "\n",
      "Validate: Average loss: 0.1694, Average Metric: -0.0004\n",
      "\n",
      "Train Epoch: 6 [0/57 (0%)]\tLoss: 0.153932\n",
      "\n",
      "Validate: Average loss: 0.1781, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 7 [0/57 (0%)]\tLoss: 0.265189\n",
      "\n",
      "Validate: Average loss: 0.1403, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 8 [0/57 (0%)]\tLoss: 0.105766\n",
      "\n",
      "Validate: Average loss: 0.1490, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 9 [0/57 (0%)]\tLoss: 0.141511\n",
      "\n",
      "Validate: Average loss: 0.1277, Average Metric: -0.0005\n",
      "\n",
      "Train Epoch: 10 [0/57 (0%)]\tLoss: 0.079429\n",
      "\n",
      "Validate: Average loss: 0.1385, Average Metric: -0.0012\n",
      "\n",
      "Train Epoch: 11 [0/57 (0%)]\tLoss: 0.128086\n",
      "\n",
      "Validate: Average loss: 0.1319, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 12 [0/57 (0%)]\tLoss: 0.193840\n",
      "\n",
      "Validate: Average loss: 0.1187, Average Metric: -0.0006\n",
      "\n",
      "Train Epoch: 13 [0/57 (0%)]\tLoss: 0.126006\n",
      "\n",
      "Validate: Average loss: 0.1195, Average Metric: -0.0005\n",
      "\n",
      "Train Epoch: 14 [0/57 (0%)]\tLoss: 0.191283\n",
      "\n",
      "Validate: Average loss: 0.1067, Average Metric: -0.0004\n",
      "\n",
      "Train Epoch: 15 [0/57 (0%)]\tLoss: 0.073849\n",
      "\n",
      "Validate: Average loss: 0.1222, Average Metric: -0.0003\n",
      "\n",
      "Train Epoch: 16 [0/57 (0%)]\tLoss: 0.118217\n",
      "\n",
      "Validate: Average loss: 0.1068, Average Metric: -0.0006\n",
      "\n",
      "Train Epoch: 17 [0/57 (0%)]\tLoss: 0.146447\n",
      "\n",
      "Validate: Average loss: 0.0995, Average Metric: -0.0004\n",
      "\n",
      "Train Epoch: 18 [0/57 (0%)]\tLoss: 0.070023\n",
      "\n",
      "Validate: Average loss: 0.1028, Average Metric: -0.0006\n",
      "\n",
      "Train Epoch: 19 [0/57 (0%)]\tLoss: 0.139403\n",
      "\n",
      "Validate: Average loss: 0.1009, Average Metric: -0.0003\n",
      "\n",
      "Train Epoch: 20 [0/57 (0%)]\tLoss: 0.074560\n",
      "\n",
      "Validate: Average loss: 0.0962, Average Metric: -0.0004\n",
      "\n",
      "Train Epoch: 21 [0/57 (0%)]\tLoss: 0.101143\n",
      "\n",
      "Validate: Average loss: 0.1061, Average Metric: -0.0000\n",
      "\n",
      "Train Epoch: 22 [0/57 (0%)]\tLoss: 0.088787\n",
      "\n",
      "Validate: Average loss: 0.1035, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 23 [0/57 (0%)]\tLoss: 0.078621\n",
      "\n",
      "Validate: Average loss: 0.0901, Average Metric: -0.0003\n",
      "\n",
      "Train Epoch: 24 [0/57 (0%)]\tLoss: 0.103854\n",
      "\n",
      "Validate: Average loss: 0.0923, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 25 [0/57 (0%)]\tLoss: 0.087351\n",
      "\n",
      "Validate: Average loss: 0.0904, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 26 [0/57 (0%)]\tLoss: 0.103452\n",
      "\n",
      "Validate: Average loss: 0.0908, Average Metric: -0.0003\n",
      "\n",
      "Train Epoch: 27 [0/57 (0%)]\tLoss: 0.100660\n",
      "\n",
      "Validate: Average loss: 0.0954, Average Metric: -0.0004\n",
      "\n",
      "Train Epoch: 28 [0/57 (0%)]\tLoss: 0.132121\n",
      "\n",
      "Validate: Average loss: 0.0916, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 29 [0/57 (0%)]\tLoss: 0.082642\n",
      "\n",
      "Validate: Average loss: 0.0904, Average Metric: 0.0000\n",
      "\n",
      "Train Epoch: 30 [0/57 (0%)]\tLoss: 0.078333\n",
      "\n",
      "Validate: Average loss: 0.0796, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 31 [0/57 (0%)]\tLoss: 0.052844\n",
      "\n",
      "Validate: Average loss: 0.0784, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 32 [0/57 (0%)]\tLoss: 0.077685\n",
      "\n",
      "Validate: Average loss: 0.0769, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 33 [0/57 (0%)]\tLoss: 0.074676\n",
      "\n",
      "Validate: Average loss: 0.0757, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 34 [0/57 (0%)]\tLoss: 0.091881\n",
      "\n",
      "Validate: Average loss: 0.0741, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 35 [0/57 (0%)]\tLoss: 0.047116\n",
      "\n",
      "Validate: Average loss: 0.0707, Average Metric: -0.0000\n",
      "\n",
      "Train Epoch: 36 [0/57 (0%)]\tLoss: 0.063879\n",
      "\n",
      "Validate: Average loss: 0.0669, Average Metric: 0.0000\n",
      "\n",
      "Train Epoch: 37 [0/57 (0%)]\tLoss: 0.048976\n",
      "\n",
      "Validate: Average loss: 0.0699, Average Metric: 0.0000\n",
      "\n",
      "Train Epoch: 38 [0/57 (0%)]\tLoss: 0.044793\n",
      "\n",
      "Validate: Average loss: 0.0612, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 39 [0/57 (0%)]\tLoss: 0.056750\n",
      "\n",
      "Validate: Average loss: 0.0672, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 40 [0/57 (0%)]\tLoss: 0.062668\n",
      "\n",
      "Validate: Average loss: 0.0630, Average Metric: -0.0000\n",
      "\n",
      "Train Epoch: 41 [0/57 (0%)]\tLoss: 0.068207\n",
      "\n",
      "Validate: Average loss: 0.0574, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 42 [0/57 (0%)]\tLoss: 0.039847\n",
      "\n",
      "Validate: Average loss: 0.0549, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 43 [0/57 (0%)]\tLoss: 0.056727\n",
      "\n",
      "Validate: Average loss: 0.0592, Average Metric: -0.0000\n",
      "\n",
      "Train Epoch: 44 [0/57 (0%)]\tLoss: 0.046454\n",
      "\n",
      "Validate: Average loss: 0.0570, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 45 [0/57 (0%)]\tLoss: 0.047456\n",
      "\n",
      "Validate: Average loss: 0.0544, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 46 [0/57 (0%)]\tLoss: 0.042278\n",
      "\n",
      "Validate: Average loss: 0.0488, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 47 [0/57 (0%)]\tLoss: 0.054217\n",
      "\n",
      "Validate: Average loss: 0.0535, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 48 [0/57 (0%)]\tLoss: 0.053013\n",
      "\n",
      "Validate: Average loss: 0.0427, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 49 [0/57 (0%)]\tLoss: 0.034270\n",
      "\n",
      "Validate: Average loss: 0.0474, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 50 [0/57 (0%)]\tLoss: 0.037392\n",
      "\n",
      "Validate: Average loss: 0.0577, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 51 [0/57 (0%)]\tLoss: 0.066857\n",
      "\n",
      "Validate: Average loss: 0.0772, Average Metric: 0.0006\n",
      "\n",
      "Train Epoch: 52 [0/57 (0%)]\tLoss: 0.056589\n",
      "\n",
      "Validate: Average loss: 0.0607, Average Metric: 0.0000\n",
      "\n",
      "Train Epoch: 53 [0/57 (0%)]\tLoss: 0.111135\n",
      "\n",
      "Validate: Average loss: 0.0440, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 54 [0/57 (0%)]\tLoss: 0.034171\n",
      "\n",
      "Validate: Average loss: 0.0440, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 55 [0/57 (0%)]\tLoss: 0.037971\n",
      "\n",
      "Validate: Average loss: 0.0431, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 56 [0/57 (0%)]\tLoss: 0.106319\n",
      "\n",
      "Validate: Average loss: 0.0399, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 57 [0/57 (0%)]\tLoss: 0.030293\n",
      "\n",
      "Validate: Average loss: 0.0361, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 58 [0/57 (0%)]\tLoss: 0.034034\n",
      "\n",
      "Validate: Average loss: 0.0376, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 59 [0/57 (0%)]\tLoss: 0.032905\n",
      "\n",
      "Validate: Average loss: 0.0353, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 60 [0/57 (0%)]\tLoss: 0.046733\n",
      "\n",
      "Validate: Average loss: 0.0333, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 61 [0/57 (0%)]\tLoss: 0.029274\n",
      "\n",
      "Validate: Average loss: 0.0385, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 62 [0/57 (0%)]\tLoss: 0.051706\n",
      "\n",
      "Validate: Average loss: 0.0335, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 63 [0/57 (0%)]\tLoss: 0.025608\n",
      "\n",
      "Validate: Average loss: 0.0372, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 64 [0/57 (0%)]\tLoss: 0.028902\n",
      "\n",
      "Validate: Average loss: 0.0357, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 65 [0/57 (0%)]\tLoss: 0.045737\n",
      "\n",
      "Validate: Average loss: 0.0355, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 66 [0/57 (0%)]\tLoss: 0.032699\n",
      "\n",
      "Validate: Average loss: 0.0326, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 67 [0/57 (0%)]\tLoss: 0.027253\n",
      "\n",
      "Validate: Average loss: 0.0323, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 68 [0/57 (0%)]\tLoss: 0.026753\n",
      "\n",
      "Validate: Average loss: 0.0318, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 69 [0/57 (0%)]\tLoss: 0.029906\n",
      "\n",
      "Validate: Average loss: 0.0326, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 70 [0/57 (0%)]\tLoss: 0.029036\n",
      "\n",
      "Validate: Average loss: 0.0430, Average Metric: 0.0002\n",
      "\n",
      "Train Epoch: 71 [0/57 (0%)]\tLoss: 0.035759\n",
      "\n",
      "Validate: Average loss: 0.0445, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 72 [0/57 (0%)]\tLoss: 0.031512\n",
      "\n",
      "Validate: Average loss: 0.0393, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 73 [0/57 (0%)]\tLoss: 0.034994\n",
      "\n",
      "Validate: Average loss: 0.0333, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 74 [0/57 (0%)]\tLoss: 0.026848\n",
      "\n",
      "Validate: Average loss: 0.0334, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 75 [0/57 (0%)]\tLoss: 0.027089\n",
      "\n",
      "Validate: Average loss: 0.0328, Average Metric: 0.0005\n",
      "\n",
      "Train Epoch: 76 [0/57 (0%)]\tLoss: 0.024550\n",
      "\n",
      "Validate: Average loss: 0.0368, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 77 [0/57 (0%)]\tLoss: 0.025452\n",
      "\n",
      "Validate: Average loss: 0.0303, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 78 [0/57 (0%)]\tLoss: 0.063736\n",
      "\n",
      "Validate: Average loss: 0.0314, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 79 [0/57 (0%)]\tLoss: 0.026045\n",
      "\n",
      "Validate: Average loss: 0.0312, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 80 [0/57 (0%)]\tLoss: 0.022693\n",
      "\n",
      "Validate: Average loss: 0.0306, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 81 [0/57 (0%)]\tLoss: 0.022477\n",
      "\n",
      "Validate: Average loss: 0.0309, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 82 [0/57 (0%)]\tLoss: 0.024002\n",
      "\n",
      "Validate: Average loss: 0.0310, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 83 [0/57 (0%)]\tLoss: 0.022173\n",
      "\n",
      "Validate: Average loss: 0.0312, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 84 [0/57 (0%)]\tLoss: 0.022328\n",
      "\n",
      "Validate: Average loss: 0.0302, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 85 [0/57 (0%)]\tLoss: 0.024531\n",
      "\n",
      "Validate: Average loss: 0.0323, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 86 [0/57 (0%)]\tLoss: 0.019892\n",
      "\n",
      "Validate: Average loss: 0.0295, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 87 [0/57 (0%)]\tLoss: 0.021873\n",
      "\n",
      "Validate: Average loss: 0.0333, Average Metric: 0.0003\n",
      "\n",
      "Train Epoch: 88 [0/57 (0%)]\tLoss: 0.019160\n",
      "\n",
      "Validate: Average loss: 0.0337, Average Metric: 0.0004\n",
      "\n",
      "Train Epoch: 89 [0/57 (0%)]\tLoss: 0.020680\n",
      "\n",
      "Validate: Average loss: 0.0307, Average Metric: 0.0006\n",
      "\n",
      "Train Epoch: 90 [0/57 (0%)]\tLoss: 0.068770\n",
      "\n",
      "Validate: Average loss: 0.1089, Average Metric: 0.0001\n",
      "\n",
      "Train Epoch: 91 [0/57 (0%)]\tLoss: 0.089600\n",
      "\n",
      "Validate: Average loss: 0.1961, Average Metric: -0.0006\n",
      "\n",
      "Train Epoch: 92 [0/57 (0%)]\tLoss: 0.253413\n",
      "\n",
      "Validate: Average loss: 0.1516, Average Metric: -0.0001\n",
      "\n",
      "Train Epoch: 93 [0/57 (0%)]\tLoss: 0.192270\n",
      "\n",
      "Validate: Average loss: 0.1248, Average Metric: -0.0006\n",
      "\n",
      "Train Epoch: 94 [0/57 (0%)]\tLoss: 0.145172\n",
      "\n",
      "Validate: Average loss: 0.1245, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 95 [0/57 (0%)]\tLoss: 0.100345\n",
      "\n",
      "Validate: Average loss: 0.1670, Average Metric: -0.0009\n",
      "\n",
      "Train Epoch: 96 [0/57 (0%)]\tLoss: 0.138801\n",
      "\n",
      "Validate: Average loss: 0.1095, Average Metric: -0.0004\n",
      "\n",
      "Train Epoch: 97 [0/57 (0%)]\tLoss: 0.081304\n",
      "\n",
      "Validate: Average loss: 0.0988, Average Metric: -0.0002\n",
      "\n",
      "Train Epoch: 98 [0/57 (0%)]\tLoss: 0.092382\n",
      "\n",
      "Validate: Average loss: 0.0896, Average Metric: 0.0000\n",
      "\n",
      "Train Epoch: 99 [0/57 (0%)]\tLoss: 0.076647\n",
      "\n",
      "Validate: Average loss: 0.0962, Average Metric: -0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: XDG_RUNTIME_DIR points to non-existing path '/run/user/1043', please create it with 0700 permissions.\n"
     ]
    }
   ],
   "source": [
    "# during the training you can inspect the \n",
    "# predictions in the tensorboard\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    # train TODO: YOUR CODE HERE add save torch.save(net, \"model.pt\")\n",
    "    train(model, train_loader, loss_function, optimizer,\n",
    "                device, epoch, tb_logger=tb_logger)\n",
    "    step = (epoch +1) * len(train_loader.dataset)\n",
    "    # validate TODO: YOUR CODE HERE\n",
    "    validate(model, val_loader, loss_function,\n",
    "                   metric, step,\n",
    "                   tb_logger=tb_logger)\n",
    "    torch.save(model, \"model_{}.pt\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ada9a41-9a1d-42a5-8c69-1404aa0d894a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44834/1308841415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m validate(model, test_loader, loss_function,\n\u001b[0;32m----> 7\u001b[0;31m                    \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                    tb_logger=tb_logger)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'step' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = model()\n",
    "#state = torch.load('./model.pt')\n",
    "#model.load_state_dict(state)\n",
    "\n",
    "model = torch.load('./model.pt')\n",
    "validate(model, test_loader, loss_function,\n",
    "                   metric, step,\n",
    "                   tb_logger=tb_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5869315-2cfe-430f-b3b2-6a8eb3b4bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DrosoMicroCT('./Project5_Drosophila_microCT_segmentation/resize2/test')\n",
    "test_loader = DataLoader(test_data, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6cb8b96-16e4-4907-93ac-a09cb6aa2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage, testlabels = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf128b5b-2c6c-4fd4-8c0d-2ff5bd4929a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage = testimage.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c80081e0-95ca-4cb7-a464-a3e53d6fdef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 5-dimensional input for 5-dimensional weight [16, 1, 3, 3, 3], but got 4-dimensional input of size [1, 128, 128, 128] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37499/4191564647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/dl-pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37499/3594734458.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mencoder_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mencoder_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl-pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl-pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl-pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl-pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/dl-pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             )\n\u001b[0;32m--> 582\u001b[0;31m         return F.conv3d(\n\u001b[0m\u001b[1;32m    583\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 5-dimensional input for 5-dimensional weight [16, 1, 3, 3, 3], but got 4-dimensional input of size [1, 128, 128, 128] instead"
     ]
    }
   ],
   "source": [
    "prediction = model(testimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5aed783-692a-45fb-930d-091bb4027f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: could not determine DPI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'y' at 0x7fbc6014f460>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimage, testlabel=iter(test_loader).next()\n",
    "testimage = testimage.to(device)\n",
    "testlabel = testlabel.long()\n",
    "prediction = model(testimage)\n",
    "predictimage = torch.argmax(prediction, dim=1)\n",
    "predictimage=predictimage.to('cpu')\n",
    "predictimage=predictimage.detach().numpy()\n",
    "np.unique(predictimage)\n",
    "testimage = testimage.to('cpu')\n",
    "viewer = napari.view_image(testimage)\n",
    "viewer.add_labels(predictimage)\n",
    "viewer.add_labels(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70e8ac-8c72-47b5-8a23-faa897bec357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL for Image Analysis (PyTorch)",
   "language": "python",
   "name": "dl-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
